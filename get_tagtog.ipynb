{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# 로그인 위치\n",
    "url = 'https://tagtog.net/-login'\n",
    "\n",
    "# 다운로드 위치\n",
    "file_url = 'https://tagtog.net/nannullna/this-is-real/-downloads/dataset-as-anndoc'\n",
    "zip_file = 'download.zip'\n",
    "\n",
    "if os.path.exists(zip_file):\n",
    "    os.remove(zip_file)\n",
    "    \n",
    "# 로그인 정보\n",
    "login_info = {\n",
    "    'loginid': '', # 아이디 입력\n",
    "    'password': '' # 비밀번호 입력\n",
    "}\n",
    "\n",
    "# 로그인\n",
    "with requests.Session() as s:\n",
    "    login_req = s.post(url, data=login_info)\n",
    "    r = s.get(file_url)\n",
    "    \n",
    "    with open(zip_file, 'wb') as output:\n",
    "        output.write(r.content)\n",
    "        \n",
    "# 압축 파일 풀기\n",
    "folder_path = './tagtog_result'\n",
    "\n",
    "zip_ = zipfile.ZipFile(zip_file)\n",
    "\n",
    "if os.path.exists(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "\n",
    "zip_.extractall(folder_path)\n",
    "\n",
    "os.remove(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = './tagtog_result'\n",
    "\n",
    "#target_folder = 'test/jeonju_hyanggyo'\n",
    "target_folder = '관광지'\n",
    "\n",
    "# 폴더 경로\n",
    "root_path = os.path.join(folder_path, 'this-is-real')\n",
    "\n",
    "json_root_path = os.path.join(root_path, 'ann.json/master/pool')\n",
    "html_root_path = os.path.join(root_path, 'plain.html/pool')\n",
    "\n",
    "json_path = os.path.join(json_root_path, target_folder)\n",
    "html_path = os.path.join(html_root_path, target_folder)\n",
    "\n",
    "def get_unique_file_name(file_name):\n",
    "    return file_name[:file_name[:file_name.rfind('.')].rfind('.')]\n",
    "\n",
    "# 파일명 목록\n",
    "file_list = [get_unique_file_name(file) for file in os.listdir(html_path)]\n",
    "\n",
    "# 파일 목록\n",
    "json_file_list = os.listdir(json_path)\n",
    "html_file_list = os.listdir(html_path)\n",
    "\n",
    "files = {}\n",
    "for file in file_list:\n",
    "    files[file] = {'json': '', 'html': ''}\n",
    "\n",
    "for json_file in json_file_list:\n",
    "    files[get_unique_file_name(json_file)]['json'] = os.path.join(json_path, json_file)\n",
    "    \n",
    "for html_file in html_file_list:\n",
    "    files[get_unique_file_name(html_file)]['html'] = os.path.join(html_path, html_file)\n",
    "\n",
    "# annotation_legend\n",
    "annotation_legend = os.path.join(root_path, 'annotations-legend.json')\n",
    "with open(annotation_legend, 'r') as f:\n",
    "    annotation_legend = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data = {\n",
    "    'title': [],\n",
    "    'sentence': [],\n",
    "    'sentence_with_entity': [],\n",
    "    'subject_entity': [],\n",
    "    'object_entity': [],\n",
    "    'subject_entity_word': [],\n",
    "    'subject_entity_start_idx': [],\n",
    "    'subject_entity_end_idx': [],\n",
    "    'subject_entity_type': [],\n",
    "    'object_entity_word': [],\n",
    "    'object_entity_start_idx': [],\n",
    "    'object_entity_end_idx': [],\n",
    "    'object_entity_type': [],    \n",
    "}\n",
    "\n",
    "for i, key in enumerate(files.keys()):\n",
    "    # get title and sentence information from html file\n",
    "    with open(files[key]['html'], 'r') as f:\n",
    "        html_obj = f.read()\n",
    "        \n",
    "    bs_obj = BeautifulSoup(html_obj, 'html.parser')\n",
    "    title, sentence = [obj.text for obj in bs_obj.select('pre')]\n",
    "\n",
    "    data['title'].append(title)\n",
    "    data['sentence'].append(sentence)\n",
    "\n",
    "\n",
    "    # get entity information from json file\n",
    "    entities = {\n",
    "        'subj': {'word': None, 'start_idx': -1, 'end_idx': -1, 'type': None},\n",
    "        'obj': {'word': None, 'start_idx': -1, 'end_idx': -1, 'type': None}\n",
    "    }\n",
    "\n",
    "    if files[key]['json'] != '':\n",
    "        with open(files[key]['json'], 'r') as f:\n",
    "            json_obj = json.load(f)\n",
    "            \n",
    "        for entity in json_obj['entities']:\n",
    "            e_info, e_type = annotation_legend[entity['classId']].split('_')\n",
    "            entities[e_info]['word'] = entity['offsets'][0]['text']\n",
    "            entities[e_info]['start_idx'] = entity['offsets'][0]['start']\n",
    "            entities[e_info]['end_idx'] = entity['offsets'][0]['start'] + len(entity['offsets'][0]['text']) - 1\n",
    "            entities[e_info]['type'] = e_type\n",
    "\n",
    "    data['subject_entity'].append(entities['subj'] if entities['subj']['word'] is not None else None)\n",
    "    data['subject_entity_word'].append(entities['subj']['word'])\n",
    "    data['subject_entity_start_idx'].append(entities['subj']['start_idx'])\n",
    "    data['subject_entity_end_idx'].append(entities['subj']['end_idx'])\n",
    "    data['subject_entity_type'].append(entities['subj']['type'])\n",
    "    data['object_entity'].append(entities['obj'] if entities['obj']['word'] is not None else None)\n",
    "    data['object_entity_word'].append(entities['obj']['word'])\n",
    "    data['object_entity_start_idx'].append(entities['obj']['start_idx'])\n",
    "    data['object_entity_end_idx'].append(entities['obj']['end_idx'])\n",
    "    data['object_entity_type'].append(entities['obj']['type']) \n",
    "\n",
    "    # get sentence with entities information\n",
    "    sentence_w_entity = sentence\n",
    "    entities['subj']['symbol'] = '$$'\n",
    "    entities['obj']['symbol'] = '@@'\n",
    "    \n",
    "    entity_list = sorted([val for val in entities.values()], key=lambda x: x['start_idx'], reverse=True)\n",
    "    for entity in entity_list:\n",
    "        if entity['word'] != '':\n",
    "            b_str = sentence_w_entity[:entity['start_idx']]\n",
    "            e_str = sentence_w_entity[entity['start_idx']:entity['end_idx']+1]\n",
    "            a_str = sentence_w_entity[entity['end_idx']+1:]            \n",
    "            sentence_w_entity = b_str + entity['symbol'] + e_str + entity['symbol'] + a_str    \n",
    "    data['sentence_with_entity'].append(sentence_w_entity)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_with_entity</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>subject_entity_word</th>\n",
       "      <th>subject_entity_start_idx</th>\n",
       "      <th>subject_entity_end_idx</th>\n",
       "      <th>subject_entity_type</th>\n",
       "      <th>object_entity_word</th>\n",
       "      <th>object_entity_start_idx</th>\n",
       "      <th>object_entity_end_idx</th>\n",
       "      <th>object_entity_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>63빌딩</td>\n",
       "      <td>9월에 대한생명(현 한화생명)이 한화그룹에 인수, 편입되면서 63빌딩 역시 한화그룹...</td>\n",
       "      <td>9월에 대한생명(현 한화생명)이 한화그룹에 인수, 편입되면서 @@63빌딩@@ 역시 ...</td>\n",
       "      <td>{'word': '한화그룹', 'start_idx': 42, 'end_idx': 4...</td>\n",
       "      <td>{'word': '63빌딩', 'start_idx': 34, 'end_idx': 3...</td>\n",
       "      <td>한화그룹</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>LOC</td>\n",
       "      <td>63빌딩</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>63빌딩</td>\n",
       "      <td>방송 당시 63빌딩의 건물 관계자가 개그맨 김경진과 함께 60층 스카이 아트 전망대...</td>\n",
       "      <td>방송 당시 $$63빌딩$$의 건물 관계자가 개그맨 김경진과 함께 @@60층 스카이 ...</td>\n",
       "      <td>{'word': '63빌딩', 'start_idx': 6, 'end_idx': 9,...</td>\n",
       "      <td>{'word': '60층 스카이 아트 전망대', 'start_idx': 32, 'e...</td>\n",
       "      <td>63빌딩</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>LOC</td>\n",
       "      <td>60층 스카이 아트 전망대</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>63빌딩</td>\n",
       "      <td>63빌딩 계단 오르기 대회는 1995년 개관 10주년을 맞이하여 대회가 열렸다.</td>\n",
       "      <td>$$63빌딩$$ 계단 오르기 대회는 @@1995년 개관 10주년@@을 맞이하여 대회...</td>\n",
       "      <td>{'word': '63빌딩', 'start_idx': 0, 'end_idx': 3,...</td>\n",
       "      <td>{'word': '1995년 개관 10주년', 'start_idx': 16, 'en...</td>\n",
       "      <td>63빌딩</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1995년 개관 10주년</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>POH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                           sentence  \\\n",
       "1158  63빌딩  9월에 대한생명(현 한화생명)이 한화그룹에 인수, 편입되면서 63빌딩 역시 한화그룹...   \n",
       "1703  63빌딩  방송 당시 63빌딩의 건물 관계자가 개그맨 김경진과 함께 60층 스카이 아트 전망대...   \n",
       "1346  63빌딩       63빌딩 계단 오르기 대회는 1995년 개관 10주년을 맞이하여 대회가 열렸다.   \n",
       "\n",
       "                                   sentence_with_entity  \\\n",
       "1158  9월에 대한생명(현 한화생명)이 한화그룹에 인수, 편입되면서 @@63빌딩@@ 역시 ...   \n",
       "1703  방송 당시 $$63빌딩$$의 건물 관계자가 개그맨 김경진과 함께 @@60층 스카이 ...   \n",
       "1346  $$63빌딩$$ 계단 오르기 대회는 @@1995년 개관 10주년@@을 맞이하여 대회...   \n",
       "\n",
       "                                         subject_entity  \\\n",
       "1158  {'word': '한화그룹', 'start_idx': 42, 'end_idx': 4...   \n",
       "1703  {'word': '63빌딩', 'start_idx': 6, 'end_idx': 9,...   \n",
       "1346  {'word': '63빌딩', 'start_idx': 0, 'end_idx': 3,...   \n",
       "\n",
       "                                          object_entity subject_entity_word  \\\n",
       "1158  {'word': '63빌딩', 'start_idx': 34, 'end_idx': 3...                한화그룹   \n",
       "1703  {'word': '60층 스카이 아트 전망대', 'start_idx': 32, 'e...                63빌딩   \n",
       "1346  {'word': '1995년 개관 10주년', 'start_idx': 16, 'en...                63빌딩   \n",
       "\n",
       "      subject_entity_start_idx  subject_entity_end_idx subject_entity_type  \\\n",
       "1158                        42                      45                 LOC   \n",
       "1703                         6                       9                 LOC   \n",
       "1346                         0                       3                 LOC   \n",
       "\n",
       "     object_entity_word  object_entity_start_idx  object_entity_end_idx  \\\n",
       "1158               63빌딩                       34                     37   \n",
       "1703     60층 스카이 아트 전망대                       32                     45   \n",
       "1346      1995년 개관 10주년                       16                     28   \n",
       "\n",
       "     object_entity_type  \n",
       "1158                LOC  \n",
       "1703                LOC  \n",
       "1346                POH  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f'{target_folder}.xlsx', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
